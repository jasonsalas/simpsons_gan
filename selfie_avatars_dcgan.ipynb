{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN for selfie images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import imageio\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from keras import initializers\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 153.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "selfies = []\n",
    "DIR = './selfies'\n",
    "\n",
    "for filename in tqdm(os.listdir(DIR)):\n",
    "    path = os.path.join(DIR, filename)\n",
    "    image = Image.open(path)\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((32, 32), Image.ANTIALIAS)\n",
    "    selfies.append(np.array(image))\n",
    "    \n",
    "np.savez('selfie_avatar.npz', selfies)\n",
    "print(np.array(selfies).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "''' load image array from disk '''\n",
    "avatar = np.load('./selfie_avatar_32.npz')\n",
    "avatar = avatar['arr_0']\n",
    "print(avatar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(avatar[i+6])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "init = initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SHALLOW MODEL @ 32-X-32 '''\n",
    "\n",
    "img_shape = (32, 32, 3)\n",
    "z_dim = 100\n",
    "init = initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "def build_discriminator(in_shape=img_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5,5), input_shape=in_shape, kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(256, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(512, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(512*4*4, input_dim=latent_dim, kernel_initializer=init))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((4, 4, 512)))\n",
    "    \n",
    "    model.add(Conv2DTranspose(256, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, (5,5), strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(3, (3,3), activation='tanh', padding='same', kernel_initializer=init))\n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "#     model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    selfie_data = np.load('./selfie_avatar_32.npz')\n",
    "    X_train = selfie_data['arr_0']\n",
    "    \n",
    "    # scale the data from the range [0, 255] to [-1, 1]\n",
    "    # to work with the hyperbolic tangent\n",
    "    X_train = (X_train.astype('float32') - 127.5) / 127.5\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "''' select real images '''\n",
    "def generate_authentic_images(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    \n",
    "    # generate authentic class labels (1)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    \n",
    "    # apply label smoothing for the range [0.7, 1.2]\n",
    "    # to make a regularizing effect\n",
    "    y = y - 0.3 + (np.random.random(y.shape) * 0.5)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "''' generate points in latent space as input for the generator '''\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    z_noise = np.random.randn(latent_dim * n_samples)\n",
    "    z_noise = z_noise.reshape(n_samples, latent_dim)\n",
    "    \n",
    "    return z_noise\n",
    "\n",
    "''' use the generator to produce synthetic images, with class labels '''\n",
    "def generate_synthetic_images(generator, latent_dim, n_samples):\n",
    "    z_noise = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(z_noise)\n",
    "    \n",
    "    # create 'synthetic' class labels (0)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "''' plot the images '''\n",
    "def save_plot(examples, epoch, n=5):\n",
    "    # rescale from the range [-1, 1] to [0, 1]\n",
    "    examples = (examples+1) / 2.0\n",
    "    \n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i])\n",
    "        \n",
    "    plt.savefig('generated_plot_e%03d.png' % (epoch+1))\n",
    "\n",
    "''' evaluate the discriminator, plot the images & save the model '''\n",
    "def summarize_performance(epoch, g, d, dataset, latent_dim, n_samples=150):\n",
    "    # prepare authentic samples\n",
    "    X_authentic, y_authentic = generate_authentic_images(dataset, n_samples)\n",
    "    _, accuracy_authentic = d.evaluate(X_authentic, y_authentic, verbose=0)\n",
    "    \n",
    "    # prepare synthetic images\n",
    "    X_synthetic, y_synthetic = generate_synthetic_images(g, latent_dim, n_samples)\n",
    "    _, accuracy_synthetic = d.evaluate(X_synthetic, y_synthetic, verbose=0)\n",
    "    \n",
    "    print('> Accuracy > authentic: %.0f%% || synthetic: %.0f%%' % (accuracy_authentic*100, accuracy_synthetic*100))\n",
    "    save_plot(X_synthetic, epoch)\n",
    "    g.save('generator_model_%03d.h5' % (epoch+1))\n",
    "\n",
    "''' train the generator and discriminator models '''\n",
    "def train(g, d, gan, dataset, latent_dim, epochs=3000, batch_size=8):\n",
    "    batch_per_epoch = int(dataset.shape[0] / batch_size)\n",
    "    half_batch = int(batch_per_epoch / 2)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(batch_per_epoch):\n",
    "            # get random batch of authentic images\n",
    "            # and update discriminator weights\n",
    "            X_authentic, y_authentic = generate_authentic_images(dataset, half_batch)\n",
    "            d_loss1, _ = d.train_on_batch(X_authentic, y_authentic)\n",
    "            \n",
    "            # get synthetic images\n",
    "            # update discriminator weights\n",
    "            X_synthetic, y_synthetic = generate_synthetic_images(g, latent_dim, half_batch)\n",
    "            d_loss2, _ = d.train_on_batch(X_synthetic, y_synthetic)\n",
    "            \n",
    "            # get points from latent space to feed to the generator\n",
    "            # and update the generator via the discriminator's error\n",
    "            # and also set the labels to (1) to encourage the generator\n",
    "            # to create more plausible images\n",
    "            z_noise = generate_latent_points(latent_dim, batch_size)\n",
    "            z_noise_labels =  np.ones((batch_size, 1))\n",
    "            g_loss = gan.train_on_batch(z_noise, z_noise_labels)\n",
    "            \n",
    "            print('>%d, %d/%d, D authentic loss: %.3f, D synthetic loss: %.3f, G loss: %.3f' % \n",
    "                 (epoch+1, batch+1, batch_per_epoch, d_loss1, d_loss2, g_loss))\n",
    "            \n",
    "        # evaluate the model's performance\n",
    "        if (epoch+1) % 200 == 0:\n",
    "            summarize_performance(epoch, g, d, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "g = build_generator(latent_dim)\n",
    "d = build_discriminator(img_shape)\n",
    "gan = build_gan(g, d)\n",
    "dataset = load_real_samples()\n",
    "train(g, d, gan, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' client to produce generator's images from latent space '''\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "MODEL = './generator_model_600_og.h5'\n",
    "\n",
    "z_noise = np.random.randn(100*25)\n",
    "z_noise = z_noise.reshape(25, 100)\n",
    "\n",
    "model = load_model(MODEL)\n",
    "X = model.predict(z_noise)\n",
    "X = (X+1) / 2.0\n",
    "\n",
    "plt.imshow(X[4])\n",
    "\n",
    "# show multiple designs\n",
    "shoe_index = 0\n",
    "fix, ax = plt.subplots(5, 5, figsize=(8, 6), sharey=False, sharex=False)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(X[shoe_index])\n",
    "        ax[i, j].axis('off')\n",
    "        shoe_index += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
